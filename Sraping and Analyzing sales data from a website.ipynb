{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Project Scope: Scraping and analyzing data from a website. This serves to gain insights on whether it has been sold by an official vendor, the ratings of the phone as well as the old initial price before discount.**","metadata":{"execution":{"iopub.status.busy":"2024-01-12T22:20:33.254053Z","iopub.execute_input":"2024-01-12T22:20:33.254599Z","iopub.status.idle":"2024-01-12T22:20:33.264557Z","shell.execute_reply.started":"2024-01-12T22:20:33.254510Z","shell.execute_reply":"2024-01-12T22:20:33.262622Z"}}},{"cell_type":"code","source":"#Import libraries\nfrom bs4 import BeautifulSoup\nimport requests\nimport pandas as pd\nimport csv","metadata":{"execution":{"iopub.status.busy":"2024-01-12T22:22:15.173060Z","iopub.execute_input":"2024-01-12T22:22:15.173550Z","iopub.status.idle":"2024-01-12T22:22:15.912876Z","shell.execute_reply.started":"2024-01-12T22:22:15.173511Z","shell.execute_reply":"2024-01-12T22:22:15.911642Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Function to format the data and print the result, since more than one page is scraped by the code.\ndef print_phone_data(phone_data_format, csv_writer):\n    for record in phone_data_format:\n        csv_writer.writerow(record)       \n","metadata":{"execution":{"iopub.status.busy":"2024-01-12T22:22:20.308287Z","iopub.execute_input":"2024-01-12T22:22:20.308752Z","iopub.status.idle":"2024-01-12T22:22:20.315536Z","shell.execute_reply.started":"2024-01-12T22:22:20.308710Z","shell.execute_reply":"2024-01-12T22:22:20.314086Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Path of the website\nbase_url = 'https://www.jumia.com.ng/mobile-phones/?shipped_from=country_local&page='\nurl_separator = '#catalog-listing'\nheaders = {'User-Agent': 'Chrome/58.0.3029.110'}\n\n# full_url = 'https://www.jumia.com.ng/mobile-phones/?shipped_from=country_local&page=50#catalog-listing'\n\nphone_data_format_all_pages = []","metadata":{"execution":{"iopub.status.busy":"2024-01-12T22:22:22.428264Z","iopub.execute_input":"2024-01-12T22:22:22.428675Z","iopub.status.idle":"2024-01-12T22:22:22.434549Z","shell.execute_reply.started":"2024-01-12T22:22:22.428638Z","shell.execute_reply":"2024-01-12T22:22:22.433022Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Loop through the pages and get the necessary data\nnum_pages_to_scrape = 50\nfor page_num in range(1, num_pages_to_scrape + 1):\n    url = base_url + str(page_num) + url_separator\n    response = requests.get(url)\n    soupcontent = BeautifulSoup(response.content, 'html.parser')\n    \n    phones = soupcontent.find_all('div', {'class': 'info'})\n    phone_data_format =[]\n    for i in phones:\n        name_element = i.find('div', {'class': 'name'})\n        price_element = i.find('div', {'class': 'prc'})\n        official_store_element = i.find('div', {'class': 'bdg _mall _xs'})\n        discount_element = i.find('div', {'class': 'bdg _dsct _sm'})\n        rating_element = i.find('div', {'class':'rev'})\n        old_element = i.find('div', {'class':'old'})\n\n##To avoid attribut error####\n\n# Check if elements are found before accessing their text\n        if name_element:\n            name = name_element.get_text().replace('\\xa0', ' ')\n        else:\n            name = 'N/A'\n\n        if price_element:\n            price = price_element.get_text().replace('\\xa0', ' ')\n        else:\n            price = 'N/A'\n\n        if official_store_element:\n            official_store = official_store_element.get_text().replace('\\xa0', ' ')\n        else:\n            official_store = 'N/A'\n\n        if discount_element:\n            discount = discount_element.get_text().replace('\\xa0', ' ')\n        else:\n            discount = 'N/A'\n        \n        if rating_element:\n            rating = rating_element.get_text().replace('\\xa0', ' ')\n        else:\n            rating = 'N/A'\n        \n        if old_element:\n            old_price = old_element.get_text().replace('\\xa0', ' ')\n        else:\n            old_price = 'N/A'\n##Attribute error ends here###\n\n##Clean the data\n#####Because the scraped data usually comes dirty, the below code block handles the cleansing in terms of handling trailing empty spaces, replacing unwanted texts, new lines and spaces.\n\n\n# Format the data\n        format_name = ' '.join(name.strip().replace('\\n', '').split())\n        format_price = ' '.join(price.strip().replace('₦', '').split())\n        format_official_store = ' '.join(official_store.strip().replace('\\n', '').split())\n        format_discount = ' '.join(discount.strip().replace('%', '').split())\n        format_rating = ' '.join(rating.strip().replace('\\n', '').split())\n        format_old = ' '.join(old_price.strip().replace('₦', '').split())\n\n    # Print formatted phone details\n        record = [format_name, format_price, format_official_store, format_discount, format_rating, format_old]\n        phone_data_format.append(record)\n    \n    # Extend the phone_data_format_all_pages list with the data from the current page\n    phone_data_format_all_pages.extend(phone_data_format)\n\n####Clean the data\n##Save it to the csv file\ncsv_file_path = 'output_scrape.csv'\nwith open(csv_file_path, 'w', newline = '', encoding = 'utf-8') as csvfile:\n    csv_writer = csv.writer(csvfile)\n    \n    # Write Header\n    csv_writer.writerow(['Phone Name', 'Price', 'Official Store', 'Discount', 'Rating', 'old price'])\n    \n    # Write data\n    print_phone_data(phone_data_format_all_pages, csv_writer)","metadata":{"execution":{"iopub.status.busy":"2024-01-12T22:24:28.814298Z","iopub.execute_input":"2024-01-12T22:24:28.814745Z","iopub.status.idle":"2024-01-12T22:25:18.358555Z","shell.execute_reply.started":"2024-01-12T22:24:28.814706Z","shell.execute_reply":"2024-01-12T22:25:18.357312Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(\"Done\")","metadata":{"execution":{"iopub.status.busy":"2024-01-12T22:25:18.360680Z","iopub.execute_input":"2024-01-12T22:25:18.361057Z","iopub.status.idle":"2024-01-12T22:25:18.367606Z","shell.execute_reply.started":"2024-01-12T22:25:18.361021Z","shell.execute_reply":"2024-01-12T22:25:18.366422Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"}]}]}